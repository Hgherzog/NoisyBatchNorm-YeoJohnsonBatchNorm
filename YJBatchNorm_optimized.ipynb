{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hgherzog/NoisyBatchNorm-YeoJohnsonBatchNorm/blob/main/YJBatchNorm_optimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is an unfinished attempt to optimize yeo johnson transform using functorch vmap. Vmap is currently not compatible with data dependendent functions and thus does not yet work."
      ],
      "metadata": {
        "id": "lwUZFjInATmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s1jxBAM0Jxr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1dcd07-f7ef-4a27-80e8-93030dafc902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting functorch\n",
            "  Downloading functorch-1.13.0-py2.py3-none-any.whl (2.1 kB)\n",
            "Requirement already satisfied: torch<1.13.1,>=1.13.0 in /usr/local/lib/python3.8/dist-packages (from functorch) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<1.13.1,>=1.13.0->functorch) (4.4.0)\n",
            "Installing collected packages: functorch\n",
            "Successfully installed functorch-1.13.0\n"
          ]
        }
      ],
      "source": [
        "import torch, math, copy\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from scipy import optimize\n",
        "!pip install functorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7ky3oIe07MN",
        "outputId": "29cb306a-ae97-4072-b99c-d0b8c9fd5f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting d2l==1.0.0-alpha1.post0\n",
            "  Downloading d2l-1.0.0a1.post0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 467 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-alpha1.post0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-alpha1.post0) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-alpha1.post0) (1.3.5)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-alpha1.post0) (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from d2l==1.0.0-alpha1.post0) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym->d2l==1.0.0-alpha1.post0) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym->d2l==1.0.0-alpha1.post0) (3.11.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.3.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (5.7.16)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 24.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (7.7.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter->d2l==1.0.0-alpha1.post0) (6.1.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (7.9.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (5.6.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (6.1.12)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (4.8.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 77.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (0.2.5)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (3.0.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets->jupyter->d2l==1.0.0-alpha1.post0) (3.6.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (5.1.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (23.2.1)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (5.7.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2<=3.0.0->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==1.0.0-alpha1.post0) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.4.0->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.5.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (1.5.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (5.0.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (2.16.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.19.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==1.0.0-alpha1.post0) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter->d2l==1.0.0-alpha1.post0) (0.5.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->d2l==1.0.0-alpha1.post0) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->d2l==1.0.0-alpha1.post0) (2022.6)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter->d2l==1.0.0-alpha1.post0) (21.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->d2l==1.0.0-alpha1.post0) (1.24.3)\n",
            "Installing collected packages: jedi, qtpy, qtconsole, matplotlib-inline, jupyter, d2l\n",
            "Successfully installed d2l-1.0.0a1.post0 jedi-0.18.2 jupyter-1.0.0 matplotlib-inline-0.1.6 qtconsole-5.4.0 qtpy-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install d2l==1.0.0-alpha1.post0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q04f161Sa9nP"
      },
      "outputs": [],
      "source": [
        "#Yeo Johnson Transformation with pytorch tensors need to update to be compatible with a pytorch tensor of arbitrary dimension\n",
        "#Base code acquired from scikit learn source code\n",
        "\n",
        "from functorch import vmap\n",
        "def yj_pos(x, lmbda):\n",
        "  eps = torch.finfo(torch.float64).eps\n",
        "  out = torch.where(abs(lmbda) < eps, torch.log(1 + x), (torch.pow(x + 1, lmbda) - 1) / lmbda)\n",
        "  return out\n",
        "\n",
        "def yj_neg(x, lmbda): \n",
        "  eps = torch.finfo(torch.float64).eps\n",
        "  out = torch.where(abs(lmbda - 2) > eps, -(torch.pow(-x + 1, 2 - lmbda) - 1) / (2 - lmbda),  -torch.log(1 - x))\n",
        "  return out\n",
        "  \n",
        "#Trying to do it with just vmap where you do vmap down the elements of the feature and then vmap that over each of the features to eliminate masking entirely\n",
        "def yj_element(x, lmbda):\n",
        "  eps = torch.finfo(torch.float64).eps\n",
        "  # torch.where( x >=)\n",
        "  # if x >= 0.0:\n",
        "  #   if abs(lmbda) < eps:\n",
        "  #     out = torch.log(1 + x)\n",
        "  #   else:  # lmbda != 0\n",
        "  #     out = (torch.pow(x + 1, lmbda) - 1) / lmbda\n",
        "  # else: \n",
        "  #   if abs(lmbda - 2) > eps:\n",
        "  #     out = -(torch.pow(-x + 1, 2 - lmbda) - 1) / (2 - lmbda)\n",
        "  #   else:  # lmbda == 2\n",
        "  #     out = -torch.log(1 - x)\n",
        "  out = torch.where(x >= 0.0, yj_pos(x, lmbda), yj_neg(x, lmbda))\n",
        "  return out\n",
        "\n",
        "  \n",
        "def _yeo_johnson_transform(x, lmbda):\n",
        "  \"\"\"Return transformed input x following Yeo-Johnson transform with\n",
        "  parameter lambda, works on single feature or channel (using it as a helper fucntion for the bigger transfrom across all feature)\n",
        "  \"\"\"\n",
        "  # out = torch.zeros_like(x)\n",
        "  # pos = x >= 0  # binary mask\n",
        "\n",
        "  # eps = torch.finfo(torch.float64).eps\n",
        "  # #when x>= 0\n",
        "  # if abs(lmbda) < eps:\n",
        "  #   out[pos] = torch.log(1 + x[pos])\n",
        "  # else:  # lmbda != 0\n",
        "  #   out[pos] = (torch.pow(x[pos] + 1, lmbda) - 1) / lmbda\n",
        "\n",
        "  # # when x < 0\n",
        "  # if abs(lmbda - 2) > eps:\n",
        "  #   out[~pos] = -(torch.pow(-x[~pos] + 1, 2 - lmbda) - 1) / (2 - lmbda)\n",
        "  # else:  # lmbda == 2\n",
        "  #   out[~pos] = -torch.log(1 +-x[~pos])\n",
        "  # pos = x >= 0  # binary mask\n",
        "  # print(lmbda)\n",
        "  ones = torch.ones(x.size()).cuda()\n",
        "  lmbda = lmbda * ones\n",
        "  lmbda = lmbda.cuda()\n",
        "  # print(lmbda)\n",
        "  # lmbda = torch.unsqueeze(lmbda, 0)\n",
        "  # print(lmbda)\n",
        "  #need to make the lambda have one lambda for each element we are mapping over\n",
        "  #we want to map over each element in the channel but this is a batch x (dim) x (dim) matrix\n",
        "  eps = torch.finfo(torch.float64).eps\n",
        "  # float_mask = torch.where(x >= 0.0, 1.0, 0.0)\n",
        "  #when x>= 0\n",
        "  #each feature has fixed lambda so this lambda\n",
        "  #Transform entire feature for a given lambda I think the 0th or first dimension of X should access this\n",
        "  yj_feature = vmap(yj_element)\n",
        "  # x = torch.unsqueeze(x, 1)\n",
        "  print(\"x shape:\", x.size())\n",
        "  print(\"lmbda shape:\", lmbda.size())\n",
        "  out = yj_feature(x, lmbda)\n",
        "  return out\n",
        "\n",
        "def YJ_Transform(X, lmbda):\n",
        "  \"\"\"Return feature or channel wise transformed input X according to the\n",
        "  Yeo-Johnson transform with parameter lambda lambda shape depends on if it is being used for a fully connected or 2D convolutional Layer\n",
        "  \"\"\"\n",
        "  # assert len(X.shape) in (2, 4)\n",
        "  if len(X.shape) == 2:\n",
        "    # When using a fully connected layer, transform X on the feature dimension\n",
        "    #I want to lambda map the yj across the features using the corresponding\n",
        "    # num_features = len(lmbda)\n",
        "    # #TODO: to write this more efficiently with some sort of lambda transformation across features\n",
        "    # features = []\n",
        "    # for i in range(num_features):\n",
        "    #   X_hat = _yeo_johnson_transform(X[i:i+1], lmbda[i])\n",
        "    #   features.append(X_hat)\n",
        "    #   #This should be the data such that the ith feature is transformed by the ith lambda value so that each of the features is mapped by same transform\n",
        "    # X_out = torch.vstack(features)\n",
        "    #vectorized version of yeo johnson\n",
        "    print(lmbda)\n",
        "    feature_transform = vmap(_yeo_johnson_transform, 1)\n",
        "    X_out = feature_transform(X, lmbda)\n",
        "\n",
        "\n",
        "  else:\n",
        "  # When using a two-dimensional convolutional layer, calculate the\n",
        "  # mean and variance on the channel dimension (axis=1). Here we\n",
        "  # need to maintain the shape of `X`, so that the broadcasting\n",
        "  # operation can be carried out later\n",
        "  #need to make sure lambda has shape of number of channels for the layer if that is what the input is\n",
        "    # num_channels = len(lmbda)\n",
        "    # channels = []\n",
        "    # #TODO: Figure out how to optimixe this to be a lambda so we don't need the for loop\n",
        "    # for i in range(num_channels):\n",
        "    #   # print(\"Channel slice for transformation\", X[:,i:, :, :].size())\n",
        "    #   X_hat = _yeo_johnson_transform(X[:,i:i+1, :, :], lmbda[i])\n",
        "    #   channels.append(X_hat)\n",
        "    # X_out = torch.cat(channels, 1)\n",
        "    print(lmbda.size())\n",
        "    print(X.size())\n",
        "    channel_transform = vmap(_yeo_johnson_transform, 1)\n",
        "    X_out = channel_transform(X, lmbda)\n",
        "  return X_out\n",
        "\n",
        "\n",
        "def _yeo_johnson_inverse_transform(x, lmbda):\n",
        "  \"\"\"Return inverse-transformed input x following Yeo-Johnson inverse\n",
        "  transform with parameter lambda, across specific feture or channel\n",
        "  \"\"\"\n",
        "  x_inv = torch.zeros_like(x)\n",
        "  pos = x >= 0.0\n",
        "\n",
        "  # when x >= 0\n",
        "  eps = torch.finfo(torch.float64).eps\n",
        "  if abs(lmbda[0]) < eps:\n",
        "    x_inv[pos] = torch.exp(x[pos]) - 1\n",
        "  else:  # lmbda != 0\n",
        "    x_inv[pos] = torch.pow(x[pos] * lmbda + 1, 1 / lmbda) - 1\n",
        "\n",
        "  # when x < 0\n",
        "  if abs(lmbda[0] - 2) > eps:\n",
        "    x_inv[~pos] = 1 - torch.pow(-(2 - lmbda) * x[~pos] + 1, 1 / (2 - lmbda))\n",
        "  else:  # lmbda == 2\n",
        "    x_inv[~pos] = 1 - torch.exp(-x[~pos])\n",
        "\n",
        "  return x_inv\n",
        "\n",
        "def YJINV_Transform(X, lmbda): \n",
        "  \"\"\"Return feature or channel wise transformed input X according to the\n",
        "  Yeo-Johnson transform with parameter lambda lambda shape depends on if it is being used for a fully connected or 2D convolutional Layer\n",
        "  \"\"\"\n",
        "  # assert len(X.shape) in (2, 4)\n",
        "  if len(X.shape) == 2:\n",
        "    # When using a fully connected layer, transform X on the feature dimension\n",
        "    #I want to lambda map the yj across the features using the corresponding\n",
        "    num_features = len(lmbda)\n",
        "    #TODO: to write this more efficiently with some sort of lambda transformation across features\n",
        "    features = []\n",
        "    for i in range(num_features):\n",
        "      X_hat = _yeo_johnson_inverse_transform(X[i:i+1], lmbda[i])\n",
        "      features.append(X_hat)\n",
        "    #This should be the data such that the ith feature is transformed by the ith lambda value so that each of the features is mapped by same transform\n",
        "    X_out = torch.vstack(features)\n",
        "\n",
        "  else:\n",
        "    # When using a two-dimensional convolutional layer, calculate the\n",
        "    # mean and variance on the channel dimension (axis=1). Here we\n",
        "    # need to maintain the shape of `X`, so that the broadcasting\n",
        "    # operation can be carried out later\n",
        "    #need to make sure lambda has shape of number of channels for the layer if that is what the input is\n",
        "    num_channels = len(lmbda)\n",
        "    channels = []\n",
        "    #TODO: Figure out how to optimixe this to be a lambda so we don't need the for loop\n",
        "    for i in range(num_channels):\n",
        "      X_hat = _yeo_johnson_inverse_transform(X[:,i:i+1, :,:], lmbda[i])\n",
        "      channels.append(X_hat)\n",
        "    X_out = torch.cat(channels, 1) #I am unsure if this stacks the things back up in the way I want it too\n",
        "    return X_out\n",
        "\n",
        "#TO:DO need to update this function so that we cna do \n",
        "def _yeo_johnson_optimize(x):\n",
        "  \"\"\"Find and return optimal lambda parameter of the Yeo-Johnson\n",
        "  transform by MLE, for observed data x. Need to do this across every feature or channel so lambda operation holds\n",
        "  Like for Box-Cox, MLE is done via the brent optimizer.\n",
        "  \"\"\"\n",
        "  #small zero like torch values \n",
        "  x_tiny = torch.finfo(torch.float64).tiny\n",
        "  #make spread of lambda values from -2, 2 spread by 0.1 calculate neg log likelihood of x over these lmbda then just pick the max put it on gpu\n",
        "  lmbda_vals = torch.linspace(-2, 2, 80).cuda()\n",
        "  num_vals = len(lmbda_vals)\n",
        "\n",
        "  def _neg_log_likelihood(lmbda):\n",
        "    \"\"\"Return the negative log likelihood of the observed data x as a\n",
        "    function of lambda.\n",
        "    \"\"\"\n",
        "    x_trans = _yeo_johnson_transform(x, lmbda)\n",
        "    n_samples = x.shape[0] #may need to edit this for pytorch tensor\n",
        "    x_trans_var = torch.var(x_trans) #Does this need to be attended to across dimensions?\n",
        "\n",
        "    # Reject transformed data that would raise a RuntimeWarning in np.log\n",
        "    # if x_trans_var < x_tiny:\n",
        "    #   return np.inf\n",
        "\n",
        "    log_var = torch.log(x_trans_var)\n",
        "    loglike = -n_samples / 2 * log_var\n",
        "    loglike += (lmbda - 1) * torch.sum(torch.sign(x) * torch.log(1 + torch.abs(x)))\n",
        "\n",
        "    return -loglike\n",
        "  NLL = vmap(_neg_log_likelihood)\n",
        "  #Need to know if you want to minimize or maximize the log likelihood\n",
        "  NLL_vals = NLL(lmbda_vals)\n",
        "  max_ind = torch.argmax(NLL_vals)\n",
        "  # max_w_storage = torch.empty_like(max_ind)\n",
        "  # # Copy the values from the original tensor to the new tensor\n",
        "  # max_w_storage.copy_(max_ind)\n",
        "  # max_ind = max_w_storage.tolist()\n",
        "  # max_ind = max_ind[0]\n",
        "  opt_mask = torch.cat(torch.zeros(int(max_ind) - 1,), torch.ones(1), torch.zeros(num_vals-max_ind,))\n",
        "  lmbda_hat = torch.sum(NLL_vals * opt_mask)\n",
        "  # lmbda_hat = lmbda_hat.tolist()\n",
        "  # lmbda_out = lmbda_hat[0]\n",
        "  #lmbda_vals[0]\n",
        "  # the computation of lambda is influenced by NaNs so we need to\n",
        "  # get rid of them make them all 0\n",
        "  # x = x[~torch.isnan(x)]\n",
        "  # choosing bracket -2, 2 like for boxcox\n",
        "  # return optimize.brent(_neg_log_likelihood, brack=(-2, 2)) #So optimize.brent seems to be not working lets list the options to fix this\n",
        "  return lmbda_hat\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#network for optimizing YJ for each thing\n",
        "class YJ_OPT(nn.Module):\n",
        "    # `num_features`: the number of outputs for a fully connected layer\n",
        "    # or the number of output channels for a convolutional layer. `num_dims`:\n",
        "    # 2 for a fully connected layer and 4 for a convolutional layer\n",
        "    #Does batch norm with data normalized to a log normal distribution\n",
        "    def __init__(self, X_shape, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        \n",
        "        self.lmbda_mle = nn.Parameter(torch.ones(X_shape))\n",
        "        self.flat = nn.Flatten(0)\n",
        "\n",
        "    def forward(self, X):\n",
        "        yj_trans = vmap(YJ_Transform, 1)\n",
        "        Y = yj_trans(X, self.lmbda_mle)\n",
        "        Y = self.flat(Y) #Does this compute an optimal lambda across all features or channels\n",
        "        return Y"
      ],
      "metadata": {
        "id": "soglIBj_W_UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = CNNtanh(k).cuda()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "8tiYSPu1cW0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkSxEp1_092D"
      },
      "outputs": [],
      "source": [
        "from d2l import torch as d2l\n",
        "#currently testing with noise addition\n",
        "def yj_batch_norm(X, gamma, beta, lmbda, moving_mean, moving_var, moving_lmbda, eps, momentum):\n",
        "    # Use `is_grad_enabled` to determine whether we are in training mode\n",
        "    if not torch.is_grad_enabled():\n",
        "        # In prediction mode, use mean and variance obtained by moving average\n",
        "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
        "        X_hat = YJ_Transform(X_hat, moving_lmbda)\n",
        "    else:\n",
        "        assert len(X.shape) in (2, 4)\n",
        "        if len(X.shape) == 2:\n",
        "            # When using a fully connected layer, calculate the mean and\n",
        "            # variance on the feature dimension\n",
        "            mean = X.mean(dim=0)\n",
        "            var = ((X - mean) ** 2).mean(dim=0)\n",
        "            # num_features = X.size(1) \n",
        "            # #want to have a little function that at each conv layer trains a lambda for all the data to be used at once\n",
        "            # steps = 100\n",
        "            # yj_opt = YJ_OPT(X.size(), num_features, 2).cuda()\n",
        "            lmbda_g = 1.7\n",
        "            lmbda_guess = lmbda_g*torch.ones(X.size())\n",
        "            # for i in range(steps):\n",
        "            #   optimizer.zero_grad()\n",
        "            #   output = yj_opt(X)\n",
        "            #   target = torch.normal(torch.zeros_like(output), torch.ones_like(output)) #should output a transformed distribution based on the learned lambda\n",
        "            #   # print(\"output:\" , output)\n",
        "            #   # print(\"target:\",target)\n",
        "            #   loss = nn.MSELoss()\n",
        "            #   l_lmbda = loss(output, target)\n",
        "            #   l_lmbda.backward(retain_graph=True)\n",
        "            #   optimizer.step()\n",
        "        else:\n",
        "            # When using a two-dimensional convolutional layer, calculate the\n",
        "            # mean and variance on the channel dimension (axis=1). Here we\n",
        "            # need to maintain the shape of `X`, so that the broadcasting\n",
        "            # operation can be carried out later\n",
        "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
        "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
        "            # num_channels = len(lmbda)\n",
        "            # lmbda_mle = torch.zeros_like(lmbda)\n",
        "            # for i in range(num_channels):\n",
        "            #   channel = X[:,i:i+1,:, :]\n",
        "            #   lmbda_mle[i] = _yeo_johnson_optimize(channel) \n",
        "            # steps = 100\n",
        "            # num_features = X.size(1)\n",
        "            # yj_opt = YJ_OPT(X.size(),num_features, 4).cuda()\n",
        "            lmbda_g = 1.7\n",
        "            lmbda_guess = lmbda_g*torch.ones(X.size())\n",
        "            lmbda_guess = lmbda_guess.cuda()\n",
        "            # for i in range(steps):\n",
        "            #   optimizer.zero_grad()\n",
        "            #   output = yj_opt(X)\n",
        "            #   target = torch.normal(torch.zeros_like(output), torch.ones_like(output)) #should output a transformed distribution based on the learned lambda\n",
        "            #   # print(\"output:\" , output.size())\n",
        "            #   # print(\"target:\",target.size())\n",
        "            #   loss = nn.MSELoss()\n",
        "            #   l_lmbda = loss(output, target)\n",
        "            #   l_lmbda.backward(retain_graph=True)\n",
        "            #   optimizer.step()\n",
        "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
        "        print(\"Size before transform:\", X_hat.size())\n",
        "        X_hat = YJ_Transform(X, lmbda_guess)\n",
        "        print(\"Size after transform:\", X_hat.size())\n",
        "        # Update the mean and variance using moving average\n",
        "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
        "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
        "        print(moving_lmbda.size()) \n",
        "        print(lmbda_guess.size())\n",
        "        moving_lmbda = (1.0 - momentum) * moving_lmbda + momentum * lmbda_guess\n",
        "        \n",
        "    #Untrasform scale and shift if needed\n",
        "    X_untrans = YJINV_Transform(X_hat, lmbda)\n",
        "    Y =  gamma*X_untrans + beta \n",
        "    return Y, moving_mean.data, moving_var.data, moving_lmbda.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fF3zF7-1KwG"
      },
      "outputs": [],
      "source": [
        "class YJ_Norm(nn.Module):\n",
        "    # `num_features`: the number of outputs for a fully connected layer\n",
        "    # or the number of output channels for a convolutional layer. `num_dims`:\n",
        "    # 2 for a fully connected layer and 4 for a convolutional layer\n",
        "    #Does batch norm with data normalized to a log normal distribution\n",
        "    def __init__(self, num_features, num_dims):\n",
        "        super().__init__()\n",
        "        if num_dims == 2:\n",
        "            shape = (1, num_features)\n",
        "        else:\n",
        "            shape = (1, num_features, 1, 1)\n",
        "        # The scale parameter and the shift parameter (model parameters) are\n",
        "        # initialized to 1 and 0, respectively\n",
        "        self.gamma = nn.Parameter(torch.ones(shape))\n",
        "        self.beta = nn.Parameter(torch.zeros(shape))\n",
        "        #The power transform parameter is initialized to 1,\n",
        "        #corresponding with the YJ identity transform\n",
        "        self.lmbda = nn.Parameter(torch.ones(shape))\n",
        "        # The variables that are not model parameters are initialized to 0 and\n",
        "        # 1\n",
        "        self.moving_mean = torch.zeros(shape)\n",
        "        self.moving_var = torch.ones(shape)\n",
        "        self.moving_lmbda = torch.ones(shape)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # If `X` is not on the main memory, copy `moving_mean` and\n",
        "        # `moving_var` to the device where `X` is located\n",
        "        if self.moving_mean.device != X.device:\n",
        "            self.moving_mean = self.moving_mean.to(X.device)\n",
        "            self.moving_var = self.moving_var.to(X.device)\n",
        "            self.moving_lmbda = self.moving_lmbda.to(X.device)\n",
        "        # Save the updated `moving_mean` and `moving_var`\n",
        "        Y, self.moving_mean, self.moving_var , self.moving_lmbda = yj_batch_norm(\n",
        "            X, self.gamma, self.beta, self.lmbda, self.moving_mean,\n",
        "            self.moving_var, self.moving_lmbda, eps=1e-5, momentum=0.1)\n",
        "        return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeLIt4XN1PCe",
        "outputId": "faae8ac5-e41d-48c2-83cc-14420da4994f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#Load dataset\n",
        "bs = 256\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "train_dataset = datasets.CIFAR10(\"data\", train=True, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\"data\", train=False, download=True, transform=transforms.Compose([\n",
        "    transforms.ToTensor(), normalize\n",
        "]))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
        "\n",
        "#Device Settings\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNlZIXB7AH4k"
      },
      "outputs": [],
      "source": [
        "#maybe I can do an alternate load with a smaller portion of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHZ3hREsxRKA"
      },
      "outputs": [],
      "source": [
        "#Train.ipynb code \n",
        "def train(epochs, model, criterion, optimizer, train_loader, test_loader):\n",
        "    epochs_and_test_err = []\n",
        "    for epoch in range(epochs):\n",
        "        train_err = train_epoch(model, criterion, optimizer, train_loader)\n",
        "        test_err = test(model, test_loader)\n",
        "        epochs_and_test_err.append((epoch, test_err))\n",
        "        print('Epoch {:03d}/{:03d}, Train Error {:.2f}% || Test Error {:.2f}%'.format(epoch, epochs, train_err*100, test_err*100))\n",
        "    return train_err, test_err, epochs_and_test_err\n",
        "    \n",
        "def train_epoch(model, criterion, optimizer, loader):\n",
        "    total_correct = 0.\n",
        "    total_samples = 0.\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        len_t = len(target)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "#I should vectorize this calculation\n",
        "        for i in range(len_t):\n",
        "          \n",
        "          total_correct +=  1 if torch.argmax(output[i]) == target[i] else 0\n",
        "          total_samples += 1\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return 1 - total_correct/total_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7kibyCtxRmO"
      },
      "outputs": [],
      "source": [
        "#Test.ipynb code\n",
        "def test(model, loader):\n",
        "  total_correct = 0.\n",
        "  total_samples = 0.\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "      if torch.cuda.is_available():\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "      output = model(data)\n",
        "#I should vectorize this transformation\n",
        "      for i, val in enumerate(target):\n",
        "        total_correct += 1 if torch.argmax(output[i]) == val else 0\n",
        "        total_samples += 1 \n",
        "\n",
        "  return 1 - total_correct/total_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvfceJiy2rcl"
      },
      "outputs": [],
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
        "\n",
        "#Do I need () or not\n",
        "# bn_dict = {'control' : nn.BatchNorm2d, 'lognorm' : BatchLogNorm, 'adanorm' : AdaBatchNorm, \n",
        "#            'pred' : PredBatchNorm, 'gauss': G_Norm, 'mean' : MeanNorm} \n",
        "\n",
        "bn_dict = {'control' : nn.BatchNorm2d,'yj_norm': YJ_Norm, 'gauss': G_Norm}\n",
        "\n",
        "\n",
        "def _weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    #print(classname)\n",
        "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
        "        init.kaiming_normal_(m.weight)\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_planes, planes, bn_type, stride=1, option='A'):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = bn_dict[bn_type](planes, 4)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = bn_dict[bn_type](planes, 4)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        #TO_DO: make it only usable for CIFAR10\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            if option == 'A':\n",
        "                \"\"\"\n",
        "                For CIFAR10 ResNet paper uses option A.\n",
        "                \"\"\"\n",
        "                self.shortcut = LambdaLayer(lambda x:\n",
        "                                            F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
        "            elif option == 'B':\n",
        "                self.shortcut = nn.Sequential(\n",
        "                     nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
        "                     nn.BatchNorm2d(self.expansion * planes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, bn_type, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = bn_dict[bn_type](16, 4)\n",
        "        self.layer1 = self._make_layer(block, 16, num_blocks[0], bn_type, stride=1)\n",
        "        self.layer2 = self._make_layer(block, 32, num_blocks[1], bn_type, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, num_blocks[2], bn_type, stride=2)\n",
        "        self.linear = nn.Linear(64, num_classes)\n",
        "\n",
        "        self.apply(_weights_init)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, bn_type, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, bn_type, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.avg_pool2d(out, out.size()[3])\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def resnet20(bn_type):\n",
        "    return ResNet(BasicBlock, [3, 3, 3], bn_type)\n",
        "\n",
        "\n",
        "def resnet32(bn_type):\n",
        "    return ResNet(BasicBlock, [5, 5, 5], bn_type)\n",
        "\n",
        "\n",
        "def resnet44(bn_type):\n",
        "    return ResNet(BasicBlock, [7, 7, 7], bn_type)\n",
        "\n",
        "\n",
        "def resnet56(bn_type):\n",
        "    return ResNet(BasicBlock, [9, 9, 9], bn_type)\n",
        "\n",
        "\n",
        "def resnet110(bn_type):\n",
        "    return ResNet(BasicBlock, [18, 18, 18], bn_type)\n",
        "\n",
        "\n",
        "def resnet1202(bn_type):\n",
        "    return ResNet(BasicBlock, [200, 200, 200], bn_type)\n",
        "\n",
        "#Number of parameters and layer testing\n",
        "# def test_net(net):\n",
        "#     import numpy as np\n",
        "#     total_params = 0\n",
        "\n",
        "#     for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
        "#         total_params += np.prod(x.data.numpy().shape)\n",
        "#     print(\"Total number of params\", total_params)\n",
        "#     print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     for net_name in __all__:\n",
        "#         if net_name.startswith('resnet'):\n",
        "#             print(net_name)\n",
        "#             test_net(globals()[net_name]())\n",
        "#             print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjcq8V3fw5wL"
      },
      "outputs": [],
      "source": [
        "lr = 0.01\n",
        "momentum = 0.9 \n",
        "epochs = 3\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "saNvErcYxHdV",
        "outputId": "0f49d4bb-7f98-4511-b8fb-bcdb7b3f28e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size before transform: torch.Size([256, 16, 32, 32])\n",
            "torch.Size([256, 16, 32, 32])\n",
            "torch.Size([256, 16, 32, 32])\n",
            "x shape: torch.Size([256, 32, 32])\n",
            "lmbda shape: torch.Size([256, 32, 32])\n",
            "Size after transform: torch.Size([16, 256, 32, 32])\n",
            "torch.Size([1, 16, 1, 1])\n",
            "torch.Size([256, 16, 32, 32])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-bb07e6f93b37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-08\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_and_test_errs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-a79d97f466d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, criterion, optimizer, train_loader, test_loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs_and_test_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtest_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mepochs_and_test_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-a79d97f466d4>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, criterion, optimizer, loader)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlen_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#I should vectorize this calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-a62cb5388a40>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-21730e2d5063>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_lmbda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_lmbda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Save the updated `moving_mean` and `moving_var`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         Y, self.moving_mean, self.moving_var , self.moving_lmbda = yj_batch_norm(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoving_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             self.moving_var, self.moving_lmbda, eps=1e-5, momentum=0.1)\n",
            "\u001b[0;32m<ipython-input-90-1bfa472ef5d1>\u001b[0m in \u001b[0;36myj_batch_norm\u001b[0;34m(X, gamma, beta, lmbda, moving_mean, moving_var, moving_lmbda, eps, momentum)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m#Untrasform scale and shift if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mX_untrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYJINV_Transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX_untrans\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoving_lmbda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-259e722b7803>\u001b[0m in \u001b[0;36mYJINV_Transform\u001b[0;34m(X, lmbda)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;31m#TODO: Figure out how to optimixe this to be a lambda so we don't need the for loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_yeo_johnson_inverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m       \u001b[0mchannels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mX_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#I am unsure if this stacks the things back up in the way I want it too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-94-259e722b7803>\u001b[0m in \u001b[0;36m_yeo_johnson_inverse_transform\u001b[0;34m(x, lmbda)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mx_inv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# lmbda != 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mx_inv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlmbda\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[0;31m# when x < 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [16, 1, 7747] cannot be broadcast to indexing result of shape [7747]"
          ]
        }
      ],
      "source": [
        "model = ResNet(BasicBlock, [3, 3, 3], 'yj_norm').cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
        "# torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "train_errs, test_errs, epochs_and_test_errs = train(epochs, model, criterion, optimizer, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "L7z600jPvXGE",
        "outputId": "c52bb152-78f7-4d08-8b28-e7a59890b3a9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-44dfc4830d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'control'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_and_test_errs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-a79d97f466d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, criterion, optimizer, train_loader, test_loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs_and_test_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtest_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mepochs_and_test_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-a79d97f466d4>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, criterion, optimizer, loader)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m           \u001b[0mtotal_correct\u001b[0m \u001b[0;34m+=\u001b[0m  \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m           \u001b[0mtotal_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Evaluation Test Loop for different models\n",
        "model = ResNet(BasicBlock, [3, 3, 3], 'control').cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "train_errs, test_errs, epochs_and_test_errs = train(epochs, model, criterion, optimizer, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nR7IaDQTxf2F",
        "outputId": "b1402c25-596e-476f-ad00-ac92c46e0205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size before transform: torch.Size([256, 16, 32, 32])\n",
            "Size after transform: torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "torch.Size([256, 512, 32])\n",
            "Size before transform: torch.Size([1, 16, 256, 512])\n",
            "Size after transform: torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "torch.Size([1, 4096, 512])\n",
            "Size before transform: torch.Size([1, 16, 1, 8192])\n",
            "Size after transform: torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n",
            "torch.Size([1, 16, 8192])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-67fda5a20f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yj_norm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_errs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_and_test_errs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-bc75fe2f8936>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epochs, model, criterion, optimizer, train_loader, test_loader)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs_and_test_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtest_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mepochs_and_test_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-bc75fe2f8936>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, criterion, optimizer, loader)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlen_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-a62cb5388a40>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-69-a62cb5388a40>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (131072) must match the size of tensor b (512) at non-singleton dimension 3"
          ]
        }
      ],
      "source": [
        "#Evaluation Test Loop for different models\n",
        "model = ResNet(BasicBlock, [3, 3, 3], 'yj_norm').cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "train_errs, test_errs, epochs_and_test_errs = train(epochs, model, criterion, optimizer, train_loader, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}